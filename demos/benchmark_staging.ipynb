{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O Benchmarking: Network vs Local Storage\n",
    "\n",
    "This notebook benchmarks different storage configurations for data extraction workflows:\n",
    "\n",
    "## Test Scenarios\n",
    "\n",
    "1. **Network → Network**: Read from `\\\\rbo-s1`, write back to `\\\\rbo-s1`\n",
    "2. **Network → Local**: Read from `\\\\rbo-s1`, write to local NVMe (`D://demo//staging`)\n",
    "3. **Local → Local**: Copy to local first, then read/write locally\n",
    "4. **Parameter Effects**: Test different processing parameters (fix_phase, use_fft, register_z)\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "- Is it faster to extract directly to network or local storage?\n",
    "- Does copying raw files to local storage first improve total workflow time?\n",
    "- How much do processing parameters affect I/O vs computation time?\n",
    "- Which file format (`.bin`, `.tiff`, `.zarr`, `.h5`) is fastest for each scenario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mbo_utilities as mbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage paths\n",
    "NETWORK_PATH = Path(r\"\\\\rbo-s1\\S1_DATA\\lbm\\demo_user\")\n",
    "LOCAL_PATH = Path(r\"D:\\demo\\staging\")\n",
    "\n",
    "# Source data\n",
    "RAW_TIFFS_NETWORK = NETWORK_PATH / \"raw_scanimage_tiffs\"\n",
    "RAW_TIFFS_LOCAL = LOCAL_PATH / \"raw_scanimage_tiffs\"\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_NETWORK = NETWORK_PATH / \"benchmark_output\"\n",
    "OUTPUT_LOCAL = LOCAL_PATH / \"benchmark_output\"\n",
    "\n",
    "# Create directories\n",
    "LOCAL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "RAW_TIFFS_LOCAL.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_NETWORK.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_LOCAL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Network path: {NETWORK_PATH}\")\n",
    "print(f\"Local path: {LOCAL_PATH}\")\n",
    "print(f\"Network path exists: {NETWORK_PATH.exists()}\")\n",
    "print(f\"Local path exists: {LOCAL_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Parameters\n",
    "\n",
    "Define different parameter combinations to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File formats to test\n",
    "FILE_FORMATS = ['.bin', '.tiff', '.zarr', '.h5']\n",
    "\n",
    "# Processing parameter sets\n",
    "PARAM_SETS = {\n",
    "    'minimal': {\n",
    "        'fix_phase': False,\n",
    "        'use_fft': False,\n",
    "        'register_z': False,\n",
    "        'description': 'No processing (fastest)'\n",
    "    },\n",
    "    'phase_only': {\n",
    "        'fix_phase': True,\n",
    "        'use_fft': False,\n",
    "        'register_z': False,\n",
    "        'description': 'Scan-phase correction only'\n",
    "    },\n",
    "    'phase_fft': {\n",
    "        'fix_phase': True,\n",
    "        'use_fft': True,\n",
    "        'register_z': False,\n",
    "        'description': 'FFT scan-phase correction'\n",
    "    },\n",
    "    'full': {\n",
    "        'fix_phase': True,\n",
    "        'use_fft': True,\n",
    "        'register_z': True,\n",
    "        'description': 'Full processing pipeline'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Subset of planes to extract (for faster testing)\n",
    "TEST_PLANES = [6, 7, 8]  # Test with 3 planes\n",
    "TEST_FRAMES = 1000  # Number of frames to extract\n",
    "\n",
    "print(\"Parameter sets to test:\")\n",
    "for name, params in PARAM_SETS.items():\n",
    "    print(f\"  {name}: {params['description']}\")\n",
    "print(f\"\\nFile formats: {FILE_FORMATS}\")\n",
    "print(f\"Test planes: {TEST_PLANES}\")\n",
    "print(f\"Test frames: {TEST_FRAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory_size(path):\n",
    "    \"\"\"Calculate total size of directory in MB\"\"\"\n",
    "    total_size = 0\n",
    "    for item in Path(path).rglob('*'):\n",
    "        if item.is_file():\n",
    "            total_size += item.stat().st_size\n",
    "    return total_size / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "def time_operation(func, *args, **kwargs):\n",
    "    \"\"\"Time a function execution\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return result, elapsed_time\n",
    "\n",
    "def copy_files_timed(src, dst):\n",
    "    \"\"\"Copy files and return time taken\"\"\"\n",
    "    start_time = time.time()\n",
    "    if dst.exists():\n",
    "        shutil.rmtree(dst)\n",
    "    shutil.copytree(src, dst)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    size_mb = get_directory_size(dst)\n",
    "    return elapsed_time, size_mb\n",
    "\n",
    "def cleanup_output(path):\n",
    "    \"\"\"Clean up output directory\"\"\"\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 1: Network → Network\n",
    "\n",
    "Read from network storage, write back to network storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_network_to_network = []\n",
    "\n",
    "# Get raw files\n",
    "raw_files = mbo.get_files(RAW_TIFFS_NETWORK)\n",
    "print(f\"Found {len(raw_files)} TIFF files on network\")\n",
    "\n",
    "for param_name, param_set in PARAM_SETS.items():\n",
    "    for file_format in FILE_FORMATS:\n",
    "        print(f\"\\nTesting: {param_name} → {file_format}\")\n",
    "        \n",
    "        # Clean output directory\n",
    "        test_output = OUTPUT_NETWORK / f\"net2net_{param_name}\"\n",
    "        cleanup_output(test_output)\n",
    "        \n",
    "        try:\n",
    "            # Load scan\n",
    "            scan = mbo.imread(raw_files)\n",
    "            scan.roi = None\n",
    "            scan.fix_phase = param_set['fix_phase']\n",
    "            scan.use_fft = param_set['use_fft']\n",
    "            \n",
    "            # Time the write operation\n",
    "            start_time = time.time()\n",
    "            mbo.imwrite(\n",
    "                scan,\n",
    "                test_output,\n",
    "                ext=file_format,\n",
    "                num_frames=TEST_FRAMES,\n",
    "                planes=TEST_PLANES,\n",
    "                overwrite=True,\n",
    "                register_z=param_set['register_z']\n",
    "            )\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Get output size\n",
    "            output_size = get_directory_size(test_output)\n",
    "            \n",
    "            # Calculate throughput\n",
    "            throughput = output_size / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            results_network_to_network.append({\n",
    "                'scenario': 'Network → Network',\n",
    "                'params': param_name,\n",
    "                'format': file_format,\n",
    "                'time_sec': elapsed_time,\n",
    "                'size_mb': output_size,\n",
    "                'throughput_mb_per_sec': throughput,\n",
    "                'success': True\n",
    "            })\n",
    "            \n",
    "            print(f\"  Time: {elapsed_time:.2f}s, Size: {output_size:.2f}MB, Throughput: {throughput:.2f}MB/s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {e}\")\n",
    "            results_network_to_network.append({\n",
    "                'scenario': 'Network → Network',\n",
    "                'params': param_name,\n",
    "                'format': file_format,\n",
    "                'time_sec': None,\n",
    "                'size_mb': None,\n",
    "                'throughput_mb_per_sec': None,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "df_net2net = pd.DataFrame(results_network_to_network)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Network → Network Results:\")\n",
    "print(df_net2net[df_net2net['success']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 2: Network → Local\n",
    "\n",
    "Read from network storage, write to local NVMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_network_to_local = []\n",
    "\n",
    "for param_name, param_set in PARAM_SETS.items():\n",
    "    for file_format in FILE_FORMATS:\n",
    "        print(f\"\\nTesting: {param_name} → {file_format}\")\n",
    "        \n",
    "        # Clean output directory\n",
    "        test_output = OUTPUT_LOCAL / f\"net2local_{param_name}\"\n",
    "        cleanup_output(test_output)\n",
    "        \n",
    "        try:\n",
    "            # Load scan from network\n",
    "            scan = mbo.imread(raw_files)\n",
    "            scan.roi = None\n",
    "            scan.fix_phase = param_set['fix_phase']\n",
    "            scan.use_fft = param_set['use_fft']\n",
    "            \n",
    "            # Time the write operation to local\n",
    "            start_time = time.time()\n",
    "            mbo.imwrite(\n",
    "                scan,\n",
    "                test_output,\n",
    "                ext=file_format,\n",
    "                num_frames=TEST_FRAMES,\n",
    "                planes=TEST_PLANES,\n",
    "                overwrite=True,\n",
    "                register_z=param_set['register_z']\n",
    "            )\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Get output size\n",
    "            output_size = get_directory_size(test_output)\n",
    "            \n",
    "            # Calculate throughput\n",
    "            throughput = output_size / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            results_network_to_local.append({\n",
    "                'scenario': 'Network → Local',\n",
    "                'params': param_name,\n",
    "                'format': file_format,\n",
    "                'time_sec': elapsed_time,\n",
    "                'size_mb': output_size,\n",
    "                'throughput_mb_per_sec': throughput,\n",
    "                'success': True\n",
    "            })\n",
    "            \n",
    "            print(f\"  Time: {elapsed_time:.2f}s, Size: {output_size:.2f}MB, Throughput: {throughput:.2f}MB/s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {e}\")\n",
    "            results_network_to_local.append({\n",
    "                'scenario': 'Network → Local',\n",
    "                'params': param_name,\n",
    "                'format': file_format,\n",
    "                'time_sec': None,\n",
    "                'size_mb': None,\n",
    "                'throughput_mb_per_sec': None,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "df_net2local = pd.DataFrame(results_network_to_local)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Network → Local Results:\")\n",
    "print(df_net2local[df_net2local['success']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 3: Copy First, Then Local → Local\n",
    "\n",
    "Copy raw files to local storage first, then process locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_copy_then_local = []\n",
    "\n",
    "# First, copy raw files to local (only once)\n",
    "print(\"Copying raw files from network to local...\")\n",
    "copy_time, copy_size = copy_files_timed(RAW_TIFFS_NETWORK, RAW_TIFFS_LOCAL)\n",
    "print(f\"Copy completed: {copy_time:.2f}s, {copy_size:.2f}MB\")\n",
    "print(f\"Copy throughput: {copy_size / copy_time:.2f}MB/s\")\n",
    "\n",
    "# Get local files\n",
    "local_files = mbo.get_files(RAW_TIFFS_LOCAL)\n",
    "print(f\"Found {len(local_files)} TIFF files locally\")\n",
    "\n",
    "for param_name, param_set in PARAM_SETS.items():\n",
    "    for file_format in FILE_FORMATS:\n",
    "        print(f\"\\nTesting: {param_name} → {file_format}\")\n",
    "        \n",
    "        # Clean output directory\n",
    "        test_output = OUTPUT_LOCAL / f\"local2local_{param_name}\"\n",
    "        cleanup_output(test_output)\n",
    "        \n",
    "        try:\n",
    "            # Load scan from local\n",
    "            scan = mbo.imread(local_files)\n",
    "            scan.roi = None\n",
    "            scan.fix_phase = param_set['fix_phase']\n",
    "            scan.use_fft = param_set['use_fft']\n",
    "            \n",
    "            # Time the write operation\n",
    "            start_time = time.time()\n",
    "            mbo.imwrite(\n",
    "                scan,\n",
    "                test_output,\n",
    "                ext=file_format,\n",
    "                num_frames=TEST_FRAMES,\n",
    "                planes=TEST_PLANES,\n",
    "                overwrite=True,\n",
    "                register_z=param_set['register_z']\n",
    "            )\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Get output size\n",
    "            output_size = get_directory_size(test_output)\n",
    "            \n",
    "            # Calculate throughput (just for processing)\n",
    "            throughput = output_size / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            # Total time includes copy time\n",
    "            total_time = copy_time + elapsed_time\n",
    "            total_throughput = output_size / total_time if total_time > 0 else 0\n",
    "            \n",
    "            results_copy_then_local.append({\n",
    "                'scenario': 'Copy + Local → Local',\n",
    "                'params': param_name,\n",
    "                'format': file_format,\n",
    "                'copy_time_sec': copy_time,\n",
    "                'process_time_sec': elapsed_time,\n",
    "                'total_time_sec': total_time,\n",
    "                'size_mb': output_size,\n",
    "                'process_throughput_mb_per_sec': throughput,\n",
    "                'total_throughput_mb_per_sec': total_throughput,\n",
    "                'success': True\n",
    "            })\n",
    "            \n",
    "            print(f\"  Process time: {elapsed_time:.2f}s, Total time: {total_time:.2f}s\")\n",
    "            print(f\"  Size: {output_size:.2f}MB, Process throughput: {throughput:.2f}MB/s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {e}\")\n",
    "            results_copy_then_local.append({\n",
    "                'scenario': 'Copy + Local → Local',\n",
    "                'params': param_name,\n",
    "                'format': file_format,\n",
    "                'copy_time_sec': copy_time,\n",
    "                'process_time_sec': None,\n",
    "                'total_time_sec': None,\n",
    "                'size_mb': None,\n",
    "                'process_throughput_mb_per_sec': None,\n",
    "                'total_throughput_mb_per_sec': None,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "df_copy_local = pd.DataFrame(results_copy_then_local)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Copy + Local → Local Results:\")\n",
    "print(df_copy_local[df_copy_local['success']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "all_results = []\n",
    "\n",
    "# Add network to network\n",
    "for r in results_network_to_network:\n",
    "    if r['success']:\n",
    "        all_results.append(r)\n",
    "\n",
    "# Add network to local\n",
    "for r in results_network_to_local:\n",
    "    if r['success']:\n",
    "        all_results.append(r)\n",
    "\n",
    "# Add copy + local (process time only for fair comparison)\n",
    "for r in results_copy_then_local:\n",
    "    if r['success']:\n",
    "        all_results.append({\n",
    "            'scenario': 'Local → Local (after copy)',\n",
    "            'params': r['params'],\n",
    "            'format': r['format'],\n",
    "            'time_sec': r['process_time_sec'],\n",
    "            'size_mb': r['size_mb'],\n",
    "            'throughput_mb_per_sec': r['process_throughput_mb_per_sec'],\n",
    "            'success': True\n",
    "        })\n",
    "\n",
    "df_all = pd.DataFrame(all_results)\n",
    "\n",
    "# Save results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_file = LOCAL_PATH / f\"benchmark_results_{timestamp}.csv\"\n",
    "df_all.to_csv(results_file, index=False)\n",
    "print(f\"Results saved to: {results_file}\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = df_all.groupby('scenario').agg({\n",
    "    'time_sec': ['mean', 'std', 'min', 'max'],\n",
    "    'throughput_mb_per_sec': ['mean', 'std', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Processing Time Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Time comparison by scenario\n",
    "ax = axes[0, 0]\n",
    "sns.boxplot(data=df_all, x='scenario', y='time_sec', ax=ax)\n",
    "ax.set_title('Processing Time by Scenario', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Time (seconds)', fontweight='bold')\n",
    "ax.set_xlabel('Scenario', fontweight='bold')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Throughput comparison by scenario\n",
    "ax = axes[0, 1]\n",
    "sns.boxplot(data=df_all, x='scenario', y='throughput_mb_per_sec', ax=ax)\n",
    "ax.set_title('Throughput by Scenario', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Throughput (MB/s)', fontweight='bold')\n",
    "ax.set_xlabel('Scenario', fontweight='bold')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Time by file format\n",
    "ax = axes[1, 0]\n",
    "sns.barplot(data=df_all, x='format', y='time_sec', hue='scenario', ax=ax)\n",
    "ax.set_title('Processing Time by File Format', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Time (seconds)', fontweight='bold')\n",
    "ax.set_xlabel('File Format', fontweight='bold')\n",
    "ax.legend(title='Scenario', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Time by parameter set\n",
    "ax = axes[1, 1]\n",
    "sns.barplot(data=df_all, x='params', y='time_sec', hue='scenario', ax=ax)\n",
    "ax.set_title('Processing Time by Parameters', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Time (seconds)', fontweight='bold')\n",
    "ax.set_xlabel('Parameter Set', fontweight='bold')\n",
    "ax.legend(title='Scenario', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOCAL_PATH / f\"benchmark_plots_{timestamp}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speedup Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate speedup relative to Network → Network baseline\n",
    "baseline = df_all[df_all['scenario'] == 'Network → Network']['time_sec'].mean()\n",
    "\n",
    "speedup_data = []\n",
    "for scenario in df_all['scenario'].unique():\n",
    "    scenario_times = df_all[df_all['scenario'] == scenario]['time_sec']\n",
    "    mean_time = scenario_times.mean()\n",
    "    speedup = baseline / mean_time\n",
    "    percent_faster = (speedup - 1) * 100\n",
    "    \n",
    "    speedup_data.append({\n",
    "        'scenario': scenario,\n",
    "        'mean_time_sec': mean_time,\n",
    "        'speedup': speedup,\n",
    "        'percent_faster': percent_faster\n",
    "    })\n",
    "\n",
    "df_speedup = pd.DataFrame(speedup_data).sort_values('speedup', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPEEDUP ANALYSIS (relative to Network → Network)\")\n",
    "print(\"=\"*80)\n",
    "print(df_speedup.to_string(index=False))\n",
    "\n",
    "# Plot speedup\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(df_speedup['scenario'], df_speedup['speedup'], \n",
    "              color=['red' if x < 1 else 'green' for x in df_speedup['speedup']],\n",
    "              alpha=0.7, edgecolor='black')\n",
    "ax.axhline(1, color='black', linestyle='--', linewidth=2, label='Baseline')\n",
    "ax.set_ylabel('Speedup Factor', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Scenario', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Speedup Relative to Network → Network', fontsize=14, fontweight='bold')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, speedup in zip(bars, df_speedup['speedup']):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{speedup:.2f}x',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOCAL_PATH / f\"speedup_analysis_{timestamp}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best configurations\n",
    "best_overall = df_all.loc[df_all['time_sec'].idxmin()]\n",
    "best_throughput = df_all.loc[df_all['throughput_mb_per_sec'].idxmax()]\n",
    "\n",
    "# Best by file format\n",
    "best_by_format = df_all.groupby('format')['time_sec'].idxmin()\n",
    "best_formats = df_all.loc[best_by_format]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. FASTEST OVERALL CONFIGURATION:\")\n",
    "print(f\"   Scenario: {best_overall['scenario']}\")\n",
    "print(f\"   Format: {best_overall['format']}\")\n",
    "print(f\"   Parameters: {best_overall['params']}\")\n",
    "print(f\"   Time: {best_overall['time_sec']:.2f}s\")\n",
    "print(f\"   Throughput: {best_overall['throughput_mb_per_sec']:.2f}MB/s\")\n",
    "\n",
    "print(\"\\n2. HIGHEST THROUGHPUT:\")\n",
    "print(f\"   Scenario: {best_throughput['scenario']}\")\n",
    "print(f\"   Format: {best_throughput['format']}\")\n",
    "print(f\"   Parameters: {best_throughput['params']}\")\n",
    "print(f\"   Throughput: {best_throughput['throughput_mb_per_sec']:.2f}MB/s\")\n",
    "\n",
    "print(\"\\n3. BEST FILE FORMATS:\")\n",
    "for _, row in best_formats.iterrows():\n",
    "    print(f\"   {row['format']}: {row['time_sec']:.2f}s ({row['scenario']})\")\n",
    "\n",
    "print(\"\\n4. WORKFLOW COMPARISON:\")\n",
    "net2net_avg = df_all[df_all['scenario'] == 'Network → Network']['time_sec'].mean()\n",
    "net2local_avg = df_all[df_all['scenario'] == 'Network → Local']['time_sec'].mean()\n",
    "local2local_avg = df_all[df_all['scenario'] == 'Local → Local (after copy)']['time_sec'].mean()\n",
    "\n",
    "print(f\"   Network → Network: {net2net_avg:.2f}s (avg)\")\n",
    "print(f\"   Network → Local: {net2local_avg:.2f}s (avg)\")\n",
    "print(f\"   Local → Local: {local2local_avg:.2f}s (avg, excluding copy time)\")\n",
    "\n",
    "if net2local_avg < net2net_avg:\n",
    "    improvement = ((net2net_avg - net2local_avg) / net2net_avg) * 100\n",
    "    print(f\"\\n   ✓ Writing to local is {improvement:.1f}% faster than network\")\n",
    "else:\n",
    "    print(f\"\\n   ✗ Network storage is faster in this configuration\")\n",
    "\n",
    "# Check if copy + process is worth it\n",
    "if len(results_copy_then_local) > 0 and results_copy_then_local[0]['success']:\n",
    "    total_with_copy = results_copy_then_local[0]['total_time_sec']\n",
    "    print(f\"\\n5. COPY STRATEGY:\")\n",
    "    print(f\"   Copy time: {copy_time:.2f}s\")\n",
    "    print(f\"   Total time (copy + process): {total_with_copy:.2f}s\")\n",
    "    if total_with_copy < net2net_avg:\n",
    "        print(f\"   ✓ Copying first is worth it for repeated processing\")\n",
    "    else:\n",
    "        print(f\"   ✗ Direct processing is faster for single runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Remove benchmark output files to free up space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up test outputs\n",
    "# shutil.rmtree(OUTPUT_NETWORK)\n",
    "# shutil.rmtree(OUTPUT_LOCAL)\n",
    "# shutil.rmtree(RAW_TIFFS_LOCAL)\n",
    "# print(\"Cleanup complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
