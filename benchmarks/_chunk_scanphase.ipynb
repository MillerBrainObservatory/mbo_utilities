{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark: Chunk I/O & File Format Save Performance\n",
    "\n",
    "Tests:\n",
    "1. Read performance at different chunk sizes (1 - 1000 MB)\n",
    "2. Save performance to different file formats using mbo_utilities.imwrite\n",
    "3. Scan phase estimation with FFT method\n",
    "\n",
    "**Reference Dataset:** `\\\\rbo-s1\\S1_DATA\\lbm\\kbarber\\2025-11-04-mk311\\raw\\green`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import mbo_utilities\n",
    "import platform\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "BENCHMARK_DATE = date.today().isoformat()\n",
    "\n",
    "print(f\"Benchmark Date: {BENCHMARK_DATE}\")\n",
    "print(f\"mbo_utilities: {mbo_utilities.__version__}\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SYSTEM INFO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"OS: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "print(f\"CPU: {platform.processor()}\")\n",
    "print(f\"CPU cores: {os.cpu_count()}\")\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"RAM: {mem.total / 1024**3:.1f} GB total, {mem.available / 1024**3:.1f} GB available ({mem.percent}% used)\")\n",
    "    disk = psutil.disk_usage('C:/')\n",
    "    print(f\"Disk (C:): {disk.total / 1024**3:.0f} GB total, {disk.free / 1024**3:.0f} GB free\")\n",
    "except ImportError:\n",
    "    print(\"(install psutil for memory/disk info)\")\n",
    "\n",
    "import numpy as np\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mbo_utilities.arrays.tiff import MboRawArray\n",
    "from mbo_utilities.phasecorr import _phase_corr_2d\n",
    "from mbo_utilities import imwrite\n",
    "\n",
    "# reference dataset\n",
    "TEST_PATH = r\"\\\\rbo-s1\\S1_DATA\\lbm\\kbarber\\2025-11-04-mk311\\raw\\green\"\n",
    "\n",
    "# test parameters\n",
    "N_FRAMES = 2000\n",
    "Z_PLANE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(TEST_PATH)\n",
    "files = sorted(list(p.glob(\"*.tif\")) + list(p.glob(\"*.tiff\")))\n",
    "print(f\"Found {len(files)} files\")\n",
    "\n",
    "arr = MboRawArray(files=files)\n",
    "arr.fix_phase = False\n",
    "print(f\"Shape: {arr.shape}\")\n",
    "print(f\"Dtype: {arr.dtype}\")\n",
    "print(f\"Z-planes: {arr.num_channels}\")\n",
    "\n",
    "# frame size\n",
    "frame_bytes = arr.shape[-2] * arr.shape[-1] * np.dtype(arr.dtype).itemsize\n",
    "frame_mb = frame_bytes / 1024 / 1024\n",
    "print(f\"\\nFrame size: {frame_bytes:,} bytes ({frame_mb:.3f} MB)\")\n",
    "print(f\"Test frames: {N_FRAMES} ({N_FRAMES * frame_mb:.1f} MB total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chunk Size Read Benchmark\n",
    "\n",
    "Test read throughput at different chunk sizes (MB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk sizes in MB\n",
    "target_mb = [1, 10, 50, 100, 250, 500, 1000]\n",
    "\n",
    "# convert to frames, cap at N_FRAMES\n",
    "chunk_configs = []\n",
    "for mb in target_mb:\n",
    "    n_frames = max(1, int(mb / frame_mb))\n",
    "    if n_frames <= N_FRAMES:\n",
    "        actual_mb = n_frames * frame_mb\n",
    "        chunk_configs.append({'target_mb': mb, 'frames': n_frames, 'actual_mb': actual_mb})\n",
    "\n",
    "print(f\"{'Target MB':<12} {'Frames':<10} {'Actual MB':<12}\")\n",
    "print(\"-\" * 35)\n",
    "for c in chunk_configs:\n",
    "    print(f\"{c['target_mb']:<12} {c['frames']:<10} {c['actual_mb']:<12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark reads\n",
    "read_results = []\n",
    "n_repeats = 3\n",
    "\n",
    "for cfg in tqdm(chunk_configs, desc=\"Chunk sizes\"):\n",
    "    n = cfg['frames']\n",
    "    times = []\n",
    "    \n",
    "    for rep in range(n_repeats):\n",
    "        # random start to avoid cache\n",
    "        max_start = max(0, min(arr.num_frames, N_FRAMES) - n - 10)\n",
    "        start = np.random.randint(0, max(1, max_start))\n",
    "        \n",
    "        t0 = time.perf_counter()\n",
    "        data = arr[start:start+n, Z_PLANE]\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    read_results.append({\n",
    "        'target_mb': cfg['target_mb'],\n",
    "        'frames': n,\n",
    "        'actual_mb': cfg['actual_mb'],\n",
    "        'time_sec': avg_time,\n",
    "        'throughput_mb_s': cfg['actual_mb'] / avg_time,\n",
    "        'ms_per_frame': avg_time * 1000 / n\n",
    "    })\n",
    "\n",
    "print(\"\\nRead Results:\")\n",
    "print(f\"{'MB':<8} {'Frames':<8} {'Time (s)':<10} {'MB/s':<10} {'ms/frame':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for r in read_results:\n",
    "    print(f\"{r['target_mb']:<8} {r['frames']:<8} {r['time_sec']:<10.2f} {r['throughput_mb_s']:<10.1f} {r['ms_per_frame']:<10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot read benchmark\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "mb_vals = [r['target_mb'] for r in read_results]\n",
    "throughput = [r['throughput_mb_s'] for r in read_results]\n",
    "ms_per_frame = [r['ms_per_frame'] for r in read_results]\n",
    "\n",
    "# throughput vs chunk size\n",
    "ax = axes[0]\n",
    "bars = ax.bar(range(len(mb_vals)), throughput, color='steelblue', alpha=0.8)\n",
    "ax.set_xticks(range(len(mb_vals)))\n",
    "ax.set_xticklabels([f\"{m}\" for m in mb_vals])\n",
    "ax.set_xlabel('Chunk Size (MB)')\n",
    "ax.set_ylabel('Throughput (MB/s)')\n",
    "ax.set_title('Read Throughput vs Chunk Size')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, val in zip(bars, throughput):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "            f'{val:.0f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# ms per frame vs chunk size\n",
    "ax = axes[1]\n",
    "bars = ax.bar(range(len(mb_vals)), ms_per_frame, color='coral', alpha=0.8)\n",
    "ax.set_xticks(range(len(mb_vals)))\n",
    "ax.set_xticklabels([f\"{m}\" for m in mb_vals])\n",
    "ax.set_xlabel('Chunk Size (MB)')\n",
    "ax.set_ylabel('Time per Frame (ms)')\n",
    "ax.set_title('Per-Frame Read Time vs Chunk Size')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, val in zip(bars, ms_per_frame):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, \n",
    "            f'{val:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. File Format Save Benchmark (mbo_utilities.imwrite)\n",
    "\n",
    "Test save performance using mbo_utilities.imwrite to different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp directory\n",
    "temp_dir = Path(tempfile.mkdtemp(prefix=\"mbo_benchmark_\"))\n",
    "print(f\"Temp dir: {temp_dir}\")\n",
    "print(f\"Testing with {N_FRAMES} frames, plane {Z_PLANE}\")\n",
    "\n",
    "save_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIFF format\n",
    "tiff_dir = temp_dir / \"tiff_out\"\n",
    "tiff_dir.mkdir()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "imwrite(arr, tiff_dir, ext=\".tiff\", planes=[Z_PLANE + 1], num_frames=N_FRAMES, overwrite=True)\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "tiff_files = list(tiff_dir.glob(\"*.tiff\")) + list(tiff_dir.glob(\"*.tif\"))\n",
    "tiff_size = sum(f.stat().st_size for f in tiff_files) / 1024 / 1024\n",
    "\n",
    "save_results.append({\n",
    "    'format': 'TIFF (.tiff)',\n",
    "    'time_sec': t1 - t0,\n",
    "    'size_mb': tiff_size,\n",
    "    'throughput_mb_s': tiff_size / (t1 - t0)\n",
    "})\n",
    "print(f\"TIFF: {t1-t0:.2f}s, {tiff_size:.1f} MB, {tiff_size/(t1-t0):.1f} MB/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zarr format\n",
    "zarr_dir = temp_dir / \"zarr_out\"\n",
    "zarr_dir.mkdir()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "imwrite(arr, zarr_dir, ext=\".zarr\", planes=[Z_PLANE + 1], num_frames=N_FRAMES, overwrite=True)\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "zarr_stores = list(zarr_dir.glob(\"*.zarr\"))\n",
    "zarr_size = sum(sum(f.stat().st_size for f in store.rglob('*') if f.is_file()) for store in zarr_stores) / 1024 / 1024\n",
    "\n",
    "save_results.append({\n",
    "    'format': 'Zarr (.zarr)',\n",
    "    'time_sec': t1 - t0,\n",
    "    'size_mb': zarr_size,\n",
    "    'throughput_mb_s': zarr_size / (t1 - t0)\n",
    "})\n",
    "print(f\"Zarr: {t1-t0:.2f}s, {zarr_size:.1f} MB, {zarr_size/(t1-t0):.1f} MB/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5 format\n",
    "h5_dir = temp_dir / \"h5_out\"\n",
    "h5_dir.mkdir()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "imwrite(arr, h5_dir, ext=\".h5\", planes=[Z_PLANE + 1], num_frames=N_FRAMES, overwrite=True)\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "h5_files = list(h5_dir.glob(\"*.h5\")) + list(h5_dir.glob(\"*.hdf5\"))\n",
    "h5_size = sum(f.stat().st_size for f in h5_files) / 1024 / 1024\n",
    "\n",
    "save_results.append({\n",
    "    'format': 'HDF5 (.h5)',\n",
    "    'time_sec': t1 - t0,\n",
    "    'size_mb': h5_size,\n",
    "    'throughput_mb_s': h5_size / (t1 - t0)\n",
    "})\n",
    "print(f\"HDF5: {t1-t0:.2f}s, {h5_size:.1f} MB, {h5_size/(t1-t0):.1f} MB/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suite2p binary format\n",
    "bin_dir = temp_dir / \"bin_out\"\n",
    "bin_dir.mkdir()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "imwrite(arr, bin_dir, ext=\".bin\", planes=[Z_PLANE + 1], num_frames=N_FRAMES, overwrite=True)\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "bin_files = list(bin_dir.rglob(\"*.bin\"))\n",
    "bin_size = sum(f.stat().st_size for f in bin_files) / 1024 / 1024\n",
    "\n",
    "save_results.append({\n",
    "    'format': 'Binary (.bin)',\n",
    "    'time_sec': t1 - t0,\n",
    "    'size_mb': bin_size,\n",
    "    'throughput_mb_s': bin_size / (t1 - t0)\n",
    "})\n",
    "print(f\"Binary: {t1-t0:.2f}s, {bin_size:.1f} MB, {bin_size/(t1-t0):.1f} MB/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot save results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "formats = [r['format'] for r in save_results]\n",
    "times = [r['time_sec'] for r in save_results]\n",
    "sizes = [r['size_mb'] for r in save_results]\n",
    "throughputs = [r['throughput_mb_s'] for r in save_results]\n",
    "\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(formats)))\n",
    "\n",
    "# save time\n",
    "ax = axes[0]\n",
    "bars = ax.barh(range(len(formats)), times, color=colors)\n",
    "ax.set_yticks(range(len(formats)))\n",
    "ax.set_yticklabels(formats)\n",
    "ax.set_xlabel('Save Time (seconds)')\n",
    "ax.set_title('Save Time by Format')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "for bar, val in zip(bars, times):\n",
    "    ax.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.1f}s', va='center', fontsize=10)\n",
    "\n",
    "# file size\n",
    "ax = axes[1]\n",
    "bars = ax.barh(range(len(formats)), sizes, color=colors)\n",
    "ax.set_yticks(range(len(formats)))\n",
    "ax.set_yticklabels(formats)\n",
    "ax.set_xlabel('File Size (MB)')\n",
    "ax.set_title('File Size by Format')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "for bar, val in zip(bars, sizes):\n",
    "    ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.0f}', va='center', fontsize=10)\n",
    "\n",
    "# throughput\n",
    "ax = axes[2]\n",
    "bars = ax.barh(range(len(formats)), throughputs, color=colors)\n",
    "ax.set_yticks(range(len(formats)))\n",
    "ax.set_yticklabels(formats)\n",
    "ax.set_xlabel('Throughput (MB/s)')\n",
    "ax.set_title('Write Throughput by Format')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "for bar, val in zip(bars, throughputs):\n",
    "    ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.0f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scan Phase Estimation (FFT Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data for phase analysis\n",
    "print(f\"Loading {N_FRAMES} frames for phase analysis...\")\n",
    "t0 = time.perf_counter()\n",
    "test_data = arr[:N_FRAMES, Z_PLANE]\n",
    "t1 = time.perf_counter()\n",
    "print(f\"Loaded in {t1-t0:.1f}s, shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test scan phase with different mean windows using FFT\n",
    "window_sizes = [1, 10, 100, 1000]\n",
    "num_samples = 5\n",
    "\n",
    "phase_results = []\n",
    "\n",
    "for ws in tqdm(window_sizes, desc=\"Window sizes\"):\n",
    "    if ws > N_FRAMES:\n",
    "        continue\n",
    "        \n",
    "    offsets = []\n",
    "    times = []\n",
    "    \n",
    "    n_possible = N_FRAMES // ws\n",
    "    n_samp = min(num_samples, n_possible)\n",
    "    starts = np.linspace(0, N_FRAMES - ws, n_samp, dtype=int)\n",
    "    \n",
    "    for start in starts:\n",
    "        t0 = time.perf_counter()\n",
    "        \n",
    "        frames = test_data[start:start+ws]\n",
    "        mean_frame = np.mean(frames, axis=0)\n",
    "        \n",
    "        # FFT phase estimation\n",
    "        offset = _phase_corr_2d(mean_frame, upsample=10, border=4, max_offset=10, use_fft=True)\n",
    "        \n",
    "        t1 = time.perf_counter()\n",
    "        offsets.append(offset)\n",
    "        times.append(t1 - t0)\n",
    "    \n",
    "    phase_results.append({\n",
    "        'window': ws,\n",
    "        'mean_offset': np.mean(offsets),\n",
    "        'std_offset': np.std(offsets),\n",
    "        'time_ms': np.mean(times) * 1000\n",
    "    })\n",
    "    \n",
    "    print(f\"Window {ws:5d}: offset = {np.mean(offsets):+.3f} +/- {np.std(offsets):.3f} px, time = {np.mean(times)*1000:.1f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot phase results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "windows = [r['window'] for r in phase_results]\n",
    "offsets = [r['mean_offset'] for r in phase_results]\n",
    "stds = [r['std_offset'] for r in phase_results]\n",
    "times_ms = [r['time_ms'] for r in phase_results]\n",
    "\n",
    "# offset with error bars\n",
    "ax = axes[0]\n",
    "ax.errorbar(windows, offsets, yerr=stds, fmt='o-', capsize=8, capthick=2, \n",
    "            markersize=10, linewidth=2, color='steelblue')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Window Size (frames)', fontsize=12)\n",
    "ax.set_ylabel('Phase Offset (pixels)', fontsize=12)\n",
    "ax.set_title('Phase Offset vs Mean Window Size (FFT method)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xticks(windows)\n",
    "ax.set_xticklabels([str(w) for w in windows])\n",
    "\n",
    "for w, o, s in zip(windows, offsets, stds):\n",
    "    ax.annotate(f'{o:.2f}+/-{s:.2f}', (w, o), textcoords='offset points', \n",
    "                xytext=(0, 15), ha='center', fontsize=9)\n",
    "\n",
    "# computation time\n",
    "ax = axes[1]\n",
    "bars = ax.bar(range(len(windows)), times_ms, color='coral', alpha=0.8)\n",
    "ax.set_xticks(range(len(windows)))\n",
    "ax.set_xticklabels([str(w) for w in windows])\n",
    "ax.set_xlabel('Window Size (frames)', fontsize=12)\n",
    "ax.set_ylabel('Computation Time (ms)', fontsize=12)\n",
    "ax.set_title('Phase Computation Time (data in memory)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, val in zip(bars, times_ms):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "            f'{val:.1f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected raw size\n",
    "raw_size_mb = N_FRAMES * frame_mb\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CHUNK & SCANPHASE BENCHMARK SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Date: {BENCHMARK_DATE}\")\n",
    "print(f\"mbo_utilities: {mbo_utilities.__version__}\")\n",
    "print(f\"Test data: {N_FRAMES} frames, {raw_size_mb:.1f} MB\")\n",
    "print()\n",
    "\n",
    "# best read chunk\n",
    "best_read = max(read_results, key=lambda x: x['throughput_mb_s'])\n",
    "print(f\"Best read chunk: {best_read['target_mb']} MB ({best_read['throughput_mb_s']:.0f} MB/s)\")\n",
    "print()\n",
    "\n",
    "# save performance\n",
    "print(\"Save performance (mbo_utilities.imwrite):\")\n",
    "for r in sorted(save_results, key=lambda x: x['time_sec']):\n",
    "    print(f\"  {r['format']:<18} {r['time_sec']:>6.1f}s  {r['size_mb']:>7.0f} MB  {r['throughput_mb_s']:>6.0f} MB/s\")\n",
    "print()\n",
    "\n",
    "# phase offset\n",
    "if phase_results:\n",
    "    best = phase_results[-1]\n",
    "    print(f\"Phase offset ({best['window']}-frame mean): {best['mean_offset']:.3f} +/- {best['std_offset']:.3f} px\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "print(f\"Cleaned up {temp_dir}\")\n",
    "\n",
    "for tf in arr.tiff_files:\n",
    "    tf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
